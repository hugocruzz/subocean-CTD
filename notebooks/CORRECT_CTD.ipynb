{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subocean and CTD data merging + correction\n",
    "The goal of this notebook is to show how the subocean data is currently beeing processed, and to have a base for asking the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List subfolders\n",
    "ctd_path = \"C:/Users/cruz/Documents/SENSE/CTD_processing/data/Level1/Forel-GroupedStn\"\n",
    "subocean_path = \"C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available subfolders:\n",
      "- StnF0\n",
      "- StnF1\n",
      "- StnF2\n",
      "- StnF3\n",
      "- StnF4\n",
      "- StnF5\n"
     ]
    }
   ],
   "source": [
    "subfolders = [f.path for f in os.scandir(ctd_path) if f.is_dir()]\n",
    "\n",
    "print(\"Available subfolders:\")\n",
    "folderlist = []\n",
    "for folder in subfolders:\n",
    "    sub_folders = folder.split(\"/\")[-1]\n",
    "    sub_folders = sub_folders.split(\"\\\\\")[-1]\n",
    "    print(f\"- {sub_folders}\")\n",
    "    folderlist.append(sub_folders)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select one of these subfolders, one correction at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_index = 4\n",
    "subfolder = folderlist[subfolder_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_ctd = os.path.join(ctd_path, subfolder)\n",
    "ctd_files = glob.glob(directory_ctd + \"/*.csv\")\n",
    "if len(ctd_files) >1:\n",
    "    print(\"Multiple CTD files found in the directory. Please select one.\")\n",
    "ctd_file_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_file = ctd_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_subocean = os.path.join(subocean_path, subfolder)\n",
    "subocean_files = glob.glob(directory_subocean + \"/*.txt\")\n",
    "subocean_logs=  glob.glob(directory_subocean + \"/*.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\\\StnF4\\\\SubOceanExperiment2024-07-07T16-48-40.txt']\n",
      "['C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\\\StnF4\\\\SubOceanExperiment2024-07-07T16-48-40.log']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Filter out elemenets of the list that dont contain the word \"subocean\"\n",
    "subocean_files = [x for x in subocean_files if \"SubOceanExperiment\" in x]\n",
    "if len(subocean_files)>1:\n",
    "    print(\"WARNING, more than one subocean file found\")\n",
    "print(subocean_files)\n",
    "print(subocean_logs)\n",
    "subocean_file_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subocean file C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\StnF4\\SubOceanExperiment2024-07-07T16-48-40.txt\n",
      "  with CTD file C:/Users/cruz/Documents/SENSE/CTD_processing/data/Level1/Forel-GroupedStn\\StnF4\\20240707_1658_idronaut.csv\n"
     ]
    }
   ],
   "source": [
    "subocean_file = subocean_files[subocean_file_index]\n",
    "subocean_log = subocean_logs[subocean_file_index]\n",
    "print(f\"Processing subocean file {subocean_file}\\n  with CTD file {ctd_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "subocean_df = pd.read_csv(subocean_file, sep='\\t')\n",
    "max_pressure_subocean = subocean_df[\"Hydrostatic pressure (bar)\"].argmax()\n",
    "subocean_df_downard = subocean_df.iloc[0:max_pressure_subocean]\n",
    "subocean_df_upward = subocean_df.iloc[max_pressure_subocean:]\n",
    "subocean_file_downward = subocean_file.replace(\".txt\", \"_downward.txt\").replace(\"raw\", \"Level0\")\n",
    "subocean_file_upward = subocean_file.replace(\".txt\", \"_upward.txt\").replace(\"raw\", \"Level0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv the downward and upward profiles\n",
    "subocean_df_downard.to_csv(subocean_file_downward, sep='\\t', index=False)\n",
    "subocean_df_upward.to_csv(subocean_file_upward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/cruz/Documents/SENSE/SubOcean/data/Level0/Forel-GroupedStn\\\\StnF4\\\\SubOceanExperiment2024-07-07T16-48-40_downward.txt'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subocean_file_downward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the two datasets (subocean and ctd data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_df = pd.read_csv(ctd_file)\n",
    "ctd_ds = ctd_df.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting for A2PS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with xarray as it'better for multidimensional data and interpolation, but it need some standardization on variable names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to make a match between the ctd and the subocean data, for that, we choose the pressure to be our matching coordinates variable. The profiles might not be done at the same time but can still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD_pressure_col = \"pressure_dbar\"#Rename \"pressure_dbar\" to \"Pres\"\n",
    "ctd_ds = ctd_ds.rename_vars({CTD_pressure_col:\"Pres\"})\n",
    "# Set 'Depth' as coordinate for both datasets and remove the original index\n",
    "ctd_ds = ctd_ds.swap_dims({'index': 'Pres'})\n",
    "ctd_ds = ctd_ds.set_coords('Pres')\n",
    "ctd_ds = ctd_ds.drop_vars('index')\n",
    "#Convert pressure in dbar to pressure in psi\n",
    "ctd_ds[\"Pres\"] = ctd_ds[\"Pres\"]*1.45038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!! CTD pressure should be in dbar while subocean should still be in bar !!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want a two way profile, so we separate the downward and upward profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pressure_ctd = ctd_ds[\"Pres\"].argmax()\n",
    "ctd_ds_downard = ctd_ds.isel(Pres=slice(None, max_pressure_ctd.values))\n",
    "#ctd_ds_downard_unique = ctd_ds_downard.groupby(\"Pres\").mean()\n",
    "ctd_ds_downard_unique = ctd_ds_downard\n",
    "ctd_ds_downard_unique[\"Oxygen_percent\"] = ctd_ds_downard_unique[\"oxygen_saturation_percent\"]*0.21\n",
    "#Rename \"pressure_dbar\" to \"Pres\"\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"Pres\":\"PrdE\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"temperature_C\":\"Tv2C\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"salinity_psu\":\"Sal2\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"Oxygen_percent\":\"Sbeox2PS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_A2PS = ctd_ds_downard_unique[[\"Tv2C\", \"Sal2\", \"Sbeox2PS\", \"PrdE\"]].to_dataframe()\n",
    "ctd_A2PS.reset_index(inplace=True, drop=True)\n",
    "#I want to drop duplicates of ctd_A2PS_int based on the PrdE column\n",
    "ctd_A2PS_not_duplicated = ctd_A2PS.drop_duplicates(subset='PrdE', keep='first')\n",
    "ctd_A2PS_not_duplicated = ctd_A2PS_not_duplicated.sort_values(by=[\"PrdE\"], ascending=True)\n",
    "formatted_ctd_file = ctd_file.replace(\".csv\", \"_downard_formatted.asc\").split(\"\\\\\")[-1]\n",
    "subocean_L0= directory_subocean.replace(\"raw\", \"Level0\")\n",
    "CTD_file_path_downward = subocean_L0 + \"/\"+ formatted_ctd_file\n",
    "ctd_A2PS_not_duplicated.to_csv(CTD_file_path_downward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pressure grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctd_ds_upward = ctd_ds.isel(Pres=slice(max_pressure_ctd.values, None))\n",
    "if len(ctd_ds_upward.Pres)>1:\n",
    "    #ctd_ds_upward_unique = ctd_ds_upward.groupby(\"Pres\").mean()\n",
    "    ctd_ds_upward_unique = ctd_ds_upward\n",
    "    ctd_ds_upward_unique[\"Oxygen_percent\"] = ctd_ds_upward_unique[\"oxygen_saturation_percent\"]*0.21\n",
    "    #Rename \"pressure_dbar\" to \"Pres\"\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"Pres\":\"PrdE\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"temperature_C\":\"Tv2C\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"salinity_psu\":\"Sal2\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"Oxygen_percent\":\"Sbeox2PS\"})\n",
    "    ctd_A2PS = ctd_ds_upward_unique[[\"Tv2C\", \"Sal2\", \"Sbeox2PS\", \"PrdE\"]].to_dataframe()\n",
    "    ctd_A2PS.reset_index(inplace=True, drop=True)\n",
    "    #I want to drop duplicates of ctd_A2PS_int based on the PrdE column\n",
    "    ctd_A2PS_not_duplicated = ctd_A2PS.drop_duplicates(subset='PrdE', keep='first')\n",
    "    ctd_A2PS_not_duplicated = ctd_A2PS_not_duplicated.sort_values(by=[\"PrdE\"], ascending=True)\n",
    "    formatted_ctd_file = ctd_file.replace(\".csv\", \"_upward_formatted.asc\").split(\"\\\\\")[-1]\n",
    "    subocean_L0= directory_subocean.replace(\"raw\", \"Level0\")\n",
    "CTD_file_path_upward = subocean_L0 + \"/\"+ formatted_ctd_file\n",
    "if len(ctd_ds_upward.Pres)>1:\n",
    "    ctd_A2PS_not_duplicated.to_csv(CTD_file_path_upward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_experiment_title(json_path, ctd_filepath, new_title):\n",
    "    \"\"\"\n",
    "    Update experiment titles in JSON file\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to JSON file\n",
    "        ctd_filepath (str): Path to CTD file\n",
    "        new_title (str): New title to assign\n",
    "    \"\"\"\n",
    "    # Read JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create new ordered dictionary for output\n",
    "    ordered_data = {}\n",
    "    \n",
    "    # First two fields\n",
    "    ordered_data[\"CTD filepath\"] = ctd_filepath\n",
    "    ordered_data[\"CTD interpolation type\"] = \"Pressure\"\n",
    "    \n",
    "    # Add all other fields from original data except the titles\n",
    "    for key, value in data.items():\n",
    "        if key not in [\"Title of the experiment\", \"Default title of the experiment\", \"CTD filepath\", \"CTD interpolation type\"]:\n",
    "            ordered_data[key] = value\n",
    "    \n",
    "    # Add title fields at the end\n",
    "    ordered_data[\"Title of the experiment\"] = new_title.split(\"\\\\\")[-1]\n",
    "    ordered_data[\"Default title of the experiment\"] = new_title.split(\"\\\\\")[-1]\n",
    "    \n",
    "    outpath = new_title.replace(\".txt\", \".log\").replace(\"raw\", \"Level0\")\n",
    "    # Write updated JSON back to file\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(ordered_data, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "json_path = subocean_log\n",
    "update_experiment_title(json_path, CTD_file_path_upward.replace(\"\\\\\", \"/\"), subocean_file_upward)\n",
    "update_experiment_title(json_path, CTD_file_path_downward.replace(\"\\\\\", \"/\"), subocean_file_downward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
