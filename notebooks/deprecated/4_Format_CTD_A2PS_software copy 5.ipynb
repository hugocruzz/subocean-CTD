{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subocean and CTD data merging + correction\n",
    "The goal of this notebook is to show how the subocean data is currently beeing processed, and to have a base for asking the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List subfolders\n",
    "ctd_path = \"C:/Users/cruz/Documents/SENSE/CTD_processing/data/Level1/Forel-GroupedStn\"\n",
    "subocean_path = \"C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available subfolders:\n",
      "- StnF0\n",
      "- StnF1\n",
      "- StnF2\n",
      "- StnF3\n",
      "- StnF4\n",
      "- StnF5\n"
     ]
    }
   ],
   "source": [
    "subfolders = [f.path for f in os.scandir(ctd_path) if f.is_dir()]\n",
    "\n",
    "print(\"Available subfolders:\")\n",
    "folderlist = []\n",
    "for folder in subfolders:\n",
    "    sub_folders = folder.split(\"/\")[-1]\n",
    "    sub_folders = sub_folders.split(\"\\\\\")[-1]\n",
    "    print(f\"- {sub_folders}\")\n",
    "    folderlist.append(sub_folders)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select one of these subfolders, one correction at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = folderlist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_ctd = os.path.join(ctd_path, subfolder)\n",
    "ctd_file = glob.glob(directory_ctd + \"/*.csv\")\n",
    "ctd_file = ctd_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/cruz/Documents/SENSE/CTD_processing/data/Level1/Forel-GroupedStn\\\\StnF4\\\\20240707_1658_idronaut.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(directory_ctd + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\\\StnF4\\\\20240707_1658_idronaut.txt', 'C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\\\StnF4\\\\SubOceanExperiment2024-07-07T16-48-40.txt']\n",
      "['C:/Users/cruz/Documents/SENSE/SubOcean/data/raw/Forel-GroupedStn\\\\StnF4\\\\SubOceanExperiment2024-07-07T16-48-40.log']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_subocean = os.path.join(subocean_path, subfolder)\n",
    "subocean_file = glob.glob(directory_subocean + \"/*.txt\")\n",
    "subocean_log=  glob.glob(directory_subocean + \"/*.log\")\n",
    "print(subocean_file)\n",
    "print(subocean_log)\n",
    "#Filter out elemenets of the list that dont contain the word \"subocean\"\n",
    "subocean_file = [x for x in subocean_file if \"SubOceanExperiment\" in x]\n",
    "subocean_file = subocean_file[0]\n",
    "subocean_log = subocean_log[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subocean_df = pd.read_csv(subocean_file, sep='\\t')\n",
    "max_pressure_subocean = subocean_df[\"Hydrostatic pressure (bar)\"].argmax()\n",
    "subocean_df_downard = subocean_df.iloc[0:max_pressure_subocean]\n",
    "subocean_df_upward = subocean_df.iloc[max_pressure_subocean:]\n",
    "subocean_file_downward = subocean_file.replace(\".txt\", \"_downward.txt\").replace(\"raw\", \"Level0\")\n",
    "subocean_file_upward = subocean_file.replace(\".txt\", \"_upward.txt\").replace(\"raw\", \"Level0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv the downward and upward profiles\n",
    "subocean_df_downard.to_csv(subocean_file_downward, sep='\\t', index=False)\n",
    "subocean_df_upward.to_csv(subocean_file_upward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the two datasets (subocean and ctd data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/cruz/Documents/SENSE/CTD_processing/data/Level1/Forel-GroupedStn\\\\StnF4\\\\20240707_1658_idronaut.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctd_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_df = pd.read_csv(ctd_file)\n",
    "ctd_ds = ctd_df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD_pressure_col = \"pressure_dbar\"#Rename \"pressure_dbar\" to \"Pres\"\n",
    "ctd_ds = ctd_ds.rename_vars({CTD_pressure_col:\"Pres\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting for A2PS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with xarray as it'better for multidimensional data and interpolation, but it need some standardization on variable names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to make a match between the ctd and the subocean data, for that, we choose the pressure to be our matching coordinates variable. The profiles might not be done at the same time but can still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Depth' as coordinate for both datasets and remove the original index\n",
    "ctd_ds = ctd_ds.swap_dims({'index': 'Pres'})\n",
    "ctd_ds = ctd_ds.set_coords('Pres')\n",
    "ctd_ds = ctd_ds.drop_vars('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want a two way profile, so we separate the downward and upward profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pressure_ctd = ctd_ds[\"Pres\"].argmax()\n",
    "ctd_ds_downard = ctd_ds.isel(Pres=slice(None, max_pressure_ctd.values))\n",
    "ctd_ds_downard_unique = ctd_ds_downard.groupby(\"Pres\").mean()\n",
    "ctd_ds_downard_unique[\"Oxygen_percent\"] = ctd_ds_downard_unique[\"oxygen_saturation_percent\"]*0.21\n",
    "#Rename \"pressure_dbar\" to \"Pres\"\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"Pres\":\"PrdE\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"temperature_C\":\"Tv2C\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"salinity_psu\":\"Sal2\"})\n",
    "ctd_ds_downard_unique = ctd_ds_downard_unique.rename_vars({\"Oxygen_percent\":\"Sbeox2PS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_A2PS = ctd_ds_downard_unique[[\"Tv2C\", \"Sal2\", \"Sbeox2PS\", \"PrdE\"]].to_dataframe()\n",
    "ctd_A2PS.reset_index(inplace=True, drop=True)\n",
    "#I want to drop duplicates of ctd_A2PS_int based on the PrdE column\n",
    "ctd_A2PS_not_duplicated = ctd_A2PS.drop_duplicates(subset='PrdE', keep='first')\n",
    "ctd_A2PS_not_duplicated = ctd_A2PS_not_duplicated.sort_values(by=[\"PrdE\"], ascending=True)\n",
    "formatted_ctd_file = ctd_file.replace(\".csv\", \"_downard_formatted.asc\").split(\"\\\\\")[-1]\n",
    "subocean_L0= directory_subocean.replace(\"raw\", \"Level0\")\n",
    "CTD_file_path_downward = subocean_L0 + \"/\"+ formatted_ctd_file\n",
    "ctd_A2PS_not_duplicated.to_csv(CTD_file_path_downward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctd_ds_upward = ctd_ds.isel(Pres=slice(max_pressure_ctd.values, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ctd_ds_upward.Pres)>1:\n",
    "    ctd_ds_upward_unique = ctd_ds_upward.groupby(\"Pres\").mean()\n",
    "    ctd_ds_upward_unique[\"Oxygen_percent\"] = ctd_ds_upward_unique[\"oxygen_saturation_percent\"]*0.21\n",
    "    #Rename \"pressure_dbar\" to \"Pres\"\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"Pres\":\"PrdE\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"temperature_C\":\"Tv2C\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"salinity_psu\":\"Sal2\"})\n",
    "    ctd_ds_upward_unique = ctd_ds_upward_unique.rename_vars({\"Oxygen_percent\":\"Sbeox2PS\"})\n",
    "    ctd_A2PS = ctd_ds_upward_unique[[\"Tv2C\", \"Sal2\", \"Sbeox2PS\", \"PrdE\"]].to_dataframe()\n",
    "    ctd_A2PS.reset_index(inplace=True, drop=True)\n",
    "    #I want to drop duplicates of ctd_A2PS_int based on the PrdE column\n",
    "    ctd_A2PS_not_duplicated = ctd_A2PS.drop_duplicates(subset='PrdE', keep='first')\n",
    "    ctd_A2PS_not_duplicated = ctd_A2PS_not_duplicated.sort_values(by=[\"PrdE\"], ascending=True)\n",
    "    formatted_ctd_file = ctd_file.replace(\".csv\", \"_upward_formatted.asc\").split(\"\\\\\")[-1]\n",
    "    subocean_L0= directory_subocean.replace(\"raw\", \"Level0\")\n",
    "CTD_file_path_upward = subocean_L0 + \"/\"+ formatted_ctd_file\n",
    "if len(ctd_ds_upward.Pres)>1:\n",
    "    ctd_A2PS_not_duplicated.to_csv(CTD_file_path_upward, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "def update_experiment_title(json_path, ctd_filepath, new_title):\n",
    "    \"\"\"\n",
    "    Update experiment titles in JSON file\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to JSON file\n",
    "        new_title (str): New title to assign\n",
    "    \"\"\"\n",
    "    # Read JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Update both title fields\n",
    "    data[\"Title of the experiment\"] = new_title.split(\"\\\\\")[-1]\n",
    "    data[\"Default title of the experiment\"] = new_title.split(\"\\\\\")[-1]\n",
    "    data[\"CTD filepath\"] = ctd_filepath\n",
    "    data[\"CTD interpolation type\"] = \"Pressure\"\n",
    "\n",
    "    outpath = new_title.replace(\".txt\", \".log\").replace(\"raw\", \"Level0\")\n",
    "    # Write updated JSON back to file\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "json_path = subocean_log\n",
    "update_experiment_title(json_path, CTD_file_path_upward, subocean_file_upward)\n",
    "update_experiment_title(json_path, CTD_file_path_downward, subocean_file_downward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
